[
    {
        "title": "OK-Robot: What Really Matters in Integrating Open-Knowledge Models for Robotics",
        "link": "https://arxiv.org/pdf/2401.12202",
        "section": "Language Models",
        "published_date": "2024-01",
        "methodology": [
            "Vision-Language Models (VLMs) - object detection",
            "LangSam, CLIP - semantic memory",
            "AnyGrasp - grasp generation",
            "State-machine model - module transitions"
        ],
        "conclusion": [
            "Pre-trained VLMs effective for navigation",
            "Grasping models viable for mobile manipulation",
            "Integration and heuristics more effective"
        ]
    },
    {
        "title": "ChatGPT for Robotics: Design Principles and Model Abilities",
        "link": "https://www.microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/chatgpt-for-robotics/",
        "section": "Language Models",
        "published_date": "2023-02",
        "methodology": ["Demonstrates the utility of ChatGPT in understanding and executing robotic tasks."],
        "conclusion": []
    },
    {
        "title": "PaLM-E: An Embodied Multimodal Language Model",
        "link": "https://palm-e.github.io/",
        "section": "Language Models",
        "published_date": "2023-06",
        "methodology": ["Development of a multimodal language model integrating visual and language inputs for robotic tasks."],
        "conclusion": []
    },
    {
        "title": "Octo: An Open-Source Generalist Robot Policy",
        "link": "https://octo-models.github.io/",
        "paper":"https://arxiv.org/pdf/2405.12213",
        "section": "Multimodal Approaches",
        "published_date": "2024-05",
        "methodology": [
            "Uses Open X-Embodiment dataset",
            "Tokenizes task descriptions and observations with Language Encoder and CNN",
            "Utilizes transformer backbone to process sequence of task and observation tokens",
            "Diffusion process applied to the embeddings for the readout tokens"
        ],
        "conclusion": [
            "Effective finetuning for new observation and action spaces with block-wise model architecture"
        ]
    },
    {
        "title": "RT-1: Robotics Transformer",
        "link": "https://robotics-transformer1.github.io/",
        "section": "Transformer Models",
        "published_date": "2022-12",
        "methodology": ["Explores the use of transformer models in robotic applications."],
        "conclusion": []
    },
    {
        "title": "RT-2: Vision-Language-Action Models",
        "link": "https://robotics-transformer2.github.io/",
        "section": "Transformer Models",
        "published_date": "2023-07",
        "methodology": ["Continues the discussion on transformer models in robotics."],
        "conclusion": []
    },
    {
        "title": "Do As I Can, Not As I Say: Grounding Language in Robotic Affordances",
        "link": "https://say-can.github.io/",
        "section": "Language Models",
        "published_date": "2022-04",
        "methodology": [
            "LLM splits high-level instructions into sub-tasks",
            "LLM scores skill likelihood based on robot capabilities and environment",
            "Quantifies success probability using Affordance functions"
        ],
        "conclusion": [
            "Improved robotics performance simply with enhanced LLMs",
            "Success when scale to complex, long-horizon tasks",
            "Simple integration of new skills, and with multilingual capabilities"
        ]
    },
    {
        "title": "Hierarchical State Space Models for Continuous Sequence-to-Sequence Modeling",
        "link": "https://arxiv.org/pdf/2402.10211",
        "section": "Transformer Models",
        "published_date": "2024-02",
        "methodology": ["Latest research on transformer models in robotics focusing on applications and results."],
        "conclusion": []
    },
    {
        "title": "Behavior Generation with Latent Actions",
        "link": "https://arxiv.org/pdf/2403.03181",
        "section": "Multimodal Approaches",
        "published_date": "2024-05",
        "methodology": ["Exploration of multimodal approaches in robotics, combining various sensor inputs for enhanced performance."],
        "conclusion": []
    },
    {
        "title": "diff History for Neural Language Agents",
        "link": "https://arxiv.org/pdf/2312.07540",
        "section": "Multimodal Approaches",
        "published_date": "2023-12",
        "methodology": ["Comprehensive study on various systems used in robotics, discussing different architectures and applications."],
        "conclusion": []
    },
    {
        "title": "On Bringing Robots Home",
        "link": "https://arxiv.org/pdf/2311.16098",
        "section": "Multimodal Approaches",
        "published_date": "2023-12",
        "methodology": ["Advanced topics in robotics, including new methodologies and technologies."],
        "conclusion": []
    },
    {
        "title": "RT-2: New model translates vision and language into action",
        "link": "https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/",
        "section": "Language Models",
        "published_date": "2023-06",
        "methodology": [],
        "conclusion": []
    },
    {
        "title": "Open X-Embodiment: Robotic Learning Datasets and RT-X Models",
        "link": "https://robotics-transformer-x.github.io/",
        "section": "Multimodal Approaches",
        "published_date": "2023-12",
        "methodology": [],
        "conclusion": []
    }
]
